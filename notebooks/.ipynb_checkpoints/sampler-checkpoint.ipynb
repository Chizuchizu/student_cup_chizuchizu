{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.69711538 8.42241379 2.13008721 5.02744425]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os, gc, sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import torch\n",
    "\n",
    "SEED = 2020\n",
    "BASE_PATH = '../data/'\n",
    "TEXT_COL = \"description\"\n",
    "TARGET = \"jobflag\"\n",
    "NUM_CLASS = 4\n",
    "N_FOLDS = 4\n",
    "MODEL_TYPE = \"bert\"\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "augmentation = True\n",
    "memo = \"single\"\n",
    "\n",
    "\n",
    "def metric_f1(labels, preds):\n",
    "    return f1_score(labels, preds, average='macro')\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "train = pd.read_csv(BASE_PATH + \"train.csv\").drop(['id'], axis=1)\n",
    "train_aug = pd.read_csv(BASE_PATH + \"train_fr_en.csv\").rename(columns={TEXT_COL: 'text', TARGET: 'label'})\n",
    "train = train.rename(columns={TEXT_COL: 'text', TARGET: 'label'})\n",
    "train['label'] -= 1\n",
    "# train[\"text\"] = train[\"text\"].str.lower()\n",
    "\n",
    "train_aug[\"label\"] -= 1\n",
    "\n",
    "length = len(train)\n",
    "train.index = range(0, length * 2, 2)\n",
    "train_aug.index = range(1, length * 2, 2)\n",
    "\n",
    "weight = len(train) / train[\"label\"].value_counts().sort_index().values\n",
    "if augmentation:\n",
    "    train = pd.concat([train, train_aug])\n",
    "    train = train.sort_index()\n",
    "\n",
    "test = pd.read_csv(BASE_PATH + \"test.csv\")\n",
    "test = test.rename(columns={TEXT_COL: 'text'}).drop(['id'], axis=1)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "train['fold_id'] = -1\n",
    "for fold, (train_idx, valid_idx) in enumerate(kfold.split(train.index, train['label'])):\n",
    "    train.loc[train.iloc[valid_idx].index, 'fold_id'] = fold\n",
    "\n",
    "X_train = train.loc[train['fold_id'] != 0]\n",
    "X_valid = train.loc[train['fold_id'] == 0]\n",
    "\n",
    "params = {\n",
    "    # \"output_dir\": \"outputs/\",\n",
    "    \"max_seq_length\": 128,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"eval_batch_size\": 64,\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"do_lower_case\": True,\n",
    "    \"manual_seed\": SEED,\n",
    "    \"verbose\": False,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"overwrite_output_dir\": True,\n",
    "}\n",
    "print(weight)\n",
    "print(type(weight))\n",
    "model = ClassificationModel(model_type=MODEL_TYPE, model_name=MODEL_NAME, num_labels=4,\n",
    "                            args=params, use_cuda=True, weight=weight.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler, RandomSampler, WeightedRandomSampler, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.SubsetRandomSampler at 0x7f5efd699070>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubsetRandomSampler([0, 1, 2, 3], RandomSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7f5e18510790> <torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7f5e18510790>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-672e29bdeff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmy_testiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_testiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_testiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_testiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/student_cup/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/student_cup/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/student_cup/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_classes = 5\n",
    "n_samples = 8\n",
    "\n",
    "mnist_train =  torchvision.datasets.MNIST(root=\"mnist/mnist_train\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor(),]))\n",
    "\n",
    "balanced_batch_sampler = SubsetRandomSampler(range(len(mnist_train)))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(mnist_train, batch_sampler=balanced_batch_sampler)\n",
    "\n",
    "my_testiter = iter(dataloader)\n",
    "print(my_testiter, my_testiter)\n",
    "images, target = my_testiter.next()\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target train 0/1: 990/10\n",
      "[[0, 1, 2, 3, -1, -2, -3, -4], [4, 5, 6, 7, -8, -5, -6, -7]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-91da59b38dec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Create subset indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# subset_idx = torch.cat(torch.Tensor((torch.arange(5), torch.arange(-5, 0)), (torch.arange(5), torch.arange(-5, 0))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msubset_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# Compute samples weight (each sample should get its own weight)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m class_sample_count = torch.tensor(\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "# Create dummy data with class imbalance 99 to 1\n",
    "numDataPoints = 1000\n",
    "data_dim = 5\n",
    "bs = 100\n",
    "data = torch.randn(numDataPoints, data_dim)\n",
    "target = torch.cat((torch.zeros(int(numDataPoints * 0.99), dtype=torch.long),\n",
    "                    torch.ones(int(numDataPoints * 0.01), dtype=torch.long)))\n",
    "\n",
    "print('target train 0/1: {}/{}'.format(\n",
    "    (target == 0).sum(), (target == 1).sum()))\n",
    "\n",
    "memo = [[0, 1, 2, 3, -1, -2, -3, -4], [4, 5, 6, 7, -8, -5, -6, -7]]\n",
    "memo = torch.tensor(memo)\n",
    "print(memo)\n",
    "# Create subset indices\n",
    "# subset_idx = torch.cat(torch.Tensor((torch.arange(5), torch.arange(-5, 0)), (torch.arange(5), torch.arange(-5, 0))))\n",
    "subset_idx = torch.cat((memo,))\n",
    "# Compute samples weight (each sample should get its own weight)\n",
    "class_sample_count = torch.tensor(\n",
    "    [(target[subset_idx] == t).sum() for t in torch.unique(target, sorted=True)])\n",
    "# weight = 1. / class_sample_count.float()\n",
    "# samples_weight = torch.tensor([weight[t] for t in target[subset_idx]])\n",
    "\n",
    "# Create sampler, dataset, loader\n",
    "# sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "sampler = SubsetRandomSampler([0, 1])\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    data[subset_idx], target[subset_idx])\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=2, num_workers=1, sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2628, -0.4125,  2.1010,  0.5633,  2.1434],\n",
       "         [-1.2275,  1.9281, -1.2357,  2.2765,  0.3411],\n",
       "         [ 1.0007,  1.8770,  1.7294,  0.8753,  0.4937],\n",
       "         [ 0.7844,  1.0188,  1.8955,  0.6821,  0.5502],\n",
       "         [ 0.3515, -1.0947, -0.7354, -1.2446, -0.5982],\n",
       "         [-0.9117,  0.1048,  0.5835, -0.9186, -0.8285],\n",
       "         [ 2.0915, -0.2989, -0.0187, -0.4907,  0.3076],\n",
       "         [-0.6244, -0.4492, -0.6091,  1.2887,  1.0613]]),\n",
       " tensor([0, 0, 0, 0, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.8487, -0.4098, -0.5212, -2.2310, -1.0961],\n",
       "          [ 1.2471, -0.4425,  1.1788, -0.2204,  0.8089],\n",
       "          [-1.0369,  0.2898, -1.0540, -0.6539, -0.1136],\n",
       "          [ 0.5492,  0.1891,  0.3625,  0.5247,  1.5407],\n",
       "          [-0.5279, -0.0289,  1.4816, -0.3087,  0.7798],\n",
       "          [-0.9649, -0.5929, -0.3412, -0.3266, -0.0257],\n",
       "          [-0.1272, -0.7001,  0.6646, -0.2318,  1.5080],\n",
       "          [-0.8094,  1.5016,  0.9072, -1.3019, -0.3740]],\n",
       " \n",
       "         [[ 0.7527, -0.3794,  0.5591, -1.8409, -0.5401],\n",
       "          [-0.9071, -0.6531,  0.6041,  0.7742, -1.5845],\n",
       "          [ 0.8196, -0.4186,  0.3631, -1.5911,  0.8281],\n",
       "          [-0.7971,  0.1316,  0.0523,  1.0176,  1.8958],\n",
       "          [-1.1283, -0.7768,  0.9692,  0.6532, -0.4897],\n",
       "          [ 1.7120,  0.6407, -0.8223,  0.3404, -0.2856],\n",
       "          [-0.8812, -0.7588,  0.9247,  0.6373, -0.7781],\n",
       "          [ 0.5911, -0.5284, -1.2771, -1.4299,  0.4362]]]),\n",
       " tensor([[0, 0, 0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1, 1]])]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "        0.0100, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
